{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from matplotlib import pyplot as plt\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit.providers.aer import StatevectorSimulator\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pandas import DataFrame\n",
    "\n",
    "sys.path.extend(['/home/quic/QUIC-Projects/'])\n",
    "from classifiers.quantum.qml.qasvm import PseudoTensorSoftQASVM\n",
    "from classifiers.datasets.sklearn import SklearnDataset\n",
    "from classifiers.quantum.ansatz import MultilayerCircuit9FeatureMap\n",
    "from classifiers.convex.svm import CvxSoftQASVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation setting\n",
    "test_size = 14780-2**13 #2**13\n",
    "n_steps = 2**10\n",
    "stepsize = 0.001\n",
    "n_feature = 10\n",
    "n_qubits_list = np.arange(6, 13+1, dtype=int) # 6 7 8 9 10 11 12 13\n",
    "n_layers_list = np.arange(1, 19+1, 2, dtype=int) # 1 3 5 7 9 11 13 15 17 19\n",
    "C=10**3\n",
    "lamda=10**3\n",
    "dir_name = 'numerical_simulation_INIT2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_and_test_data(dataset, train_size:float=2**13, test_size:float=2**7, reproducible_seed:int=None):\n",
    "    data = dataset.data.to_numpy()\n",
    "    label = dataset.target.to_numpy().astype(float)\n",
    "    # label = np.where(label%2, 1, 0)\n",
    "    mask = (label==0) + (label==1)\n",
    "    data = data[mask]\n",
    "    label = label[mask]\n",
    "    if reproducible_seed is None:\n",
    "        reproducible_seed = np.random.randint(99999)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, train_size=train_size, test_size=test_size, random_state=reproducible_seed)\n",
    "    return X_train, y_train, X_test, y_test, reproducible_seed\n",
    "\n",
    "def reduce_and_normalize_data(n_components, X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = pca.transform(X_test)\n",
    "    for i, d in enumerate(X_train):\n",
    "        X_train[i] = d/np.linalg.norm(d)\n",
    "    for i, d in enumerate(X_test):\n",
    "        X_test[i] = d/np.linalg.norm(d)\n",
    "    return X_train, X_test\n",
    "\n",
    "def construct_training_and_test_quantum_kernel_matrix(feature_map:QuantumCircuit, X_train:np.ndarray, X_test:np.ndarray):\n",
    "    quantum_instance = QuantumInstance(backend = StatevectorSimulator(device='CPU')) # TODO: gpu vs cpu\n",
    "    quantum_kernel = QuantumKernel(feature_map=feature_map, quantum_instance=quantum_instance, enforce_psd=False)\n",
    "    training_kernel = quantum_kernel.evaluate(X_train, X_train)\n",
    "    test_kernel = quantum_kernel.evaluate(X_train, X_test)\n",
    "    return training_kernel, test_kernel\n",
    "\n",
    "def train_and_test_reference(cvxsvm:CvxSoftQASVM, train_kernel:np.ndarray, test_kernel:np.ndarray, y_train:np.ndarray, y_test:np.ndarray):\n",
    "    cvxsvm.fit(train_kernel, y_train)\n",
    "    fvec = cvxsvm.f(test_kernel.T)\n",
    "    accuarcy = cvxsvm.accuracy(test_kernel.T, y_test)\n",
    "    cost = cvxsvm.dual_objective_value\n",
    "    return fvec, accuarcy, cost\n",
    "\n",
    "def epsilon(fvec, true_fvec):\n",
    "    return np.sqrt(np.mean(np.abs(fvec-true_fvec)**2)).item()\n",
    "\n",
    "def make_figure(df:DataFrame):\n",
    "    fig, ax = plt.subplots()\n",
    "    mappable = ax.imshow(df, cmap='binary')\n",
    "    ax.set_xlabel('n_qubits')\n",
    "    ax.set_ylabel('n_layers')\n",
    "    ax.set_xticks(np.arange(len(n_qubits_list)))\n",
    "    ax.set_yticks(np.arange(len(n_layers_list)))\n",
    "    ax.set_xticklabels(n_qubits_list)\n",
    "    ax.set_yticklabels(n_layers_list)\n",
    "    fig.colorbar(mappable)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mnist data set\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "dir_path = Path.cwd() / dir_name\n",
    "dir_path.mkdir(parents=True, exist_ok=True)\n",
    "dataset = fetch_openml('mnist_784')\n",
    "print('loaded mnist data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 1 layers (seed: 88731)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 3 layers (seed: 39298)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 5 layers (seed: 43795)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 7 layers (seed: 23729)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 9 layers (seed: 89596)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 11 layers (seed: 87910)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 13 layers (seed: 1488)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 15 layers (seed: 87922)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 17 layers (seed: 12522)\n",
      "64 X 64 train kernel matrix and 64 X 6588 test kernel matrix generated for 19 layers (seed: 11075)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 1 layers (seed: 83199)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 3 layers (seed: 2142)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 5 layers (seed: 75203)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 7 layers (seed: 67976)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 9 layers (seed: 4878)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 11 layers (seed: 68083)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 13 layers (seed: 41308)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 15 layers (seed: 57925)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 17 layers (seed: 50057)\n",
      "128 X 128 train kernel matrix and 128 X 6588 test kernel matrix generated for 19 layers (seed: 94827)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 1 layers (seed: 40640)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 3 layers (seed: 50177)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 5 layers (seed: 59736)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 7 layers (seed: 13360)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 9 layers (seed: 54441)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 11 layers (seed: 58926)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 13 layers (seed: 78126)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 15 layers (seed: 90704)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 17 layers (seed: 60546)\n",
      "256 X 256 train kernel matrix and 256 X 6588 test kernel matrix generated for 19 layers (seed: 25150)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 1 layers (seed: 18549)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 3 layers (seed: 42304)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 5 layers (seed: 30081)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 7 layers (seed: 50092)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 9 layers (seed: 18012)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 11 layers (seed: 46474)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 13 layers (seed: 55251)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 15 layers (seed: 87022)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 17 layers (seed: 67855)\n",
      "512 X 512 train kernel matrix and 512 X 6588 test kernel matrix generated for 19 layers (seed: 31926)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 1 layers (seed: 97719)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 3 layers (seed: 82364)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 5 layers (seed: 59820)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 7 layers (seed: 50558)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 9 layers (seed: 37213)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 11 layers (seed: 81092)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 13 layers (seed: 37061)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 15 layers (seed: 53398)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 17 layers (seed: 83559)\n",
      "1024 X 1024 train kernel matrix and 1024 X 6588 test kernel matrix generated for 19 layers (seed: 28161)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 1 layers (seed: 97367)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 3 layers (seed: 35536)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 5 layers (seed: 56298)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 7 layers (seed: 16192)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 9 layers (seed: 64287)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 11 layers (seed: 65479)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 13 layers (seed: 49506)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 15 layers (seed: 97868)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 17 layers (seed: 18683)\n",
      "2048 X 2048 train kernel matrix and 2048 X 6588 test kernel matrix generated for 19 layers (seed: 82209)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 1 layers (seed: 66917)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 3 layers (seed: 40861)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 5 layers (seed: 50762)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 7 layers (seed: 94942)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 9 layers (seed: 45957)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 11 layers (seed: 86308)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 13 layers (seed: 88359)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 15 layers (seed: 36076)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 17 layers (seed: 75721)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 19 layers (seed: 86809)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 1 layers (seed: 69304)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 3 layers (seed: 13726)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 5 layers (seed: 59557)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 7 layers (seed: 38709)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 9 layers (seed: 65460)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 11 layers (seed: 79961)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 13 layers (seed: 54248)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 15 layers (seed: 29659)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 17 layers (seed: 29641)\n",
      "8192 X 8192 train kernel matrix and 8192 X 6588 test kernel matrix generated for 19 layers (seed: 93990)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "if dir_path.joinpath('epsilon_summary').exists():\n",
    "    epsilon_summary = read_csv(dir_path.joinpath('epsilon_summary'), index_col=0)\n",
    "    epsilon_summary.columns = epsilon_summary.columns.astype(int)\n",
    "else:\n",
    "    epsilon_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('delta_summary').exists():\n",
    "    delta_summary = read_csv(dir_path.joinpath('delta_summary'), index_col=0)\n",
    "    delta_summary.columns = delta_summary.columns.astype(int)\n",
    "else:\n",
    "    delta_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('accuracy_summary').exists():\n",
    "    accuracy_summary = read_csv(dir_path.joinpath('accuracy_summary'), index_col=0)\n",
    "    accuracy_summary.columns = accuracy_summary.columns.astype(int)\n",
    "else:\n",
    "    accuracy_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('reference_accuracy_summary').exists():\n",
    "    reference_accuracy_summary = read_csv(dir_path.joinpath('reference_accuracy_summary'), index_col=0)\n",
    "    reference_accuracy_summary.columns = reference_accuracy_summary.columns.astype(int)\n",
    "else:\n",
    "    reference_accuracy_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('reference_cost_summary').exists():\n",
    "    reference_cost_summary = read_csv(dir_path.joinpath('reference_cost_summary'), index_col=0)\n",
    "    reference_cost_summary.columns = reference_cost_summary.columns.astype(int)\n",
    "else:\n",
    "    reference_cost_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "\n",
    "summary_writer = SummaryWriter(log_dir=dir_path)\n",
    "feature_map = ZZFeatureMap(feature_dimension=n_feature, reps=2, entanglement='linear')\n",
    "for n_qubits in n_qubits_list:\n",
    "    sub_dir_path = dir_path / f'n_qubits={n_qubits}'\n",
    "    sub_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    train_size = 2**n_qubits\n",
    "\n",
    "    # ansatz setup\n",
    "    device:qml.Device = qml.device('lightning.qubit', wires=n_qubits) # TODO: gpu vs cpu\n",
    "    for n_layers in n_layers_list:\n",
    "        sub_sub_dir_path = sub_dir_path / f'n_layers={n_layers}'\n",
    "        sub_sub_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        if not sub_sub_dir_path.joinpath('result.json').exists():\n",
    "            writer = SummaryWriter(log_dir=sub_sub_dir_path)\n",
    "            # data loading\n",
    "            if not sub_sub_dir_path.joinpath('reference.json').exists():\n",
    "                X_train, y_train, X_test, y_test, reproducible_seed = load_train_and_test_data(dataset, train_size=train_size, test_size=test_size)\n",
    "                X_train, X_test = reduce_and_normalize_data(n_feature, X_train, X_test)\n",
    "                train_kernel, test_kernel = construct_training_and_test_quantum_kernel_matrix(feature_map=feature_map, X_train=X_train, X_test=X_test)\n",
    "                print(f'{train_size} X {train_size} train kernel matrix and {train_size} X {test_size} test kernel matrix generated for {n_layers} layers (seed: {reproducible_seed})')\n",
    "                # set reference\n",
    "                cvxsvm = CvxSoftQASVM(kernel='precomputed', C=C, lamda=lamda)\n",
    "                true_fvec, true_accuarcy, true_cost = train_and_test_reference(cvxsvm, train_kernel, test_kernel, y_train, y_test)\n",
    "                reference_accuracy_summary[n_qubits][n_layers] = true_accuarcy\n",
    "                reference_cost_summary[n_qubits][n_layers] = true_cost\n",
    "                summary_writer.add_figure('Reference/cost', make_figure(reference_cost_summary))\n",
    "                summary_writer.add_figure('Reference/accuracy', make_figure(reference_accuracy_summary))\n",
    "                # save reference key\n",
    "                with open(sub_sub_dir_path/'reference.json', 'w') as fp:\n",
    "                    json.dump(dict(\n",
    "                        accuracy=true_accuarcy, last_cost = true_cost, fvec=true_fvec, seed = reproducible_seed\n",
    "                    ), fp=fp, default=list)\n",
    "            else:\n",
    "                with open(sub_sub_dir_path/'reference.json', 'r') as fp:\n",
    "                    reference = json.load(fp=fp)\n",
    "                true_accuarcy, true_cost = reference['accuracy'], reference['last_cost']\n",
    "                true_fvec = np.array(reference['fvec'])\n",
    "                reproducible_seed = reference['seed']\n",
    "                print(f'Reference loaded for {n_qubits} qubits {n_layers} layers (seed: {reproducible_seed})')\n",
    "                X_train, y_train, X_test, y_test, _ = load_train_and_test_data(dataset, train_size=train_size, test_size=test_size, reproducible_seed=reproducible_seed)\n",
    "                X_train, X_test = reduce_and_normalize_data(n_feature, X_train, X_test)\n",
    "                train_kernel, test_kernel = construct_training_and_test_quantum_kernel_matrix(feature_map=feature_map, X_train=X_train, X_test=X_test)\n",
    "                print(f'{train_size} X {train_size} train kernel matrix and {train_size} X {test_size} test kernel matrix generated for {n_layers} layers (seed: {reproducible_seed})')\n",
    "            # training\n",
    "            def var_form(params):\n",
    "                L = int(len(params)/2)\n",
    "                for w in device.wires:\n",
    "                    qml.Hadamard(wires=w)\n",
    "                for l in range(L):\n",
    "                    qml.BasicEntanglerLayers(params[2*l:2*l+1, :], wires=device.wires, rotation=qml.RY)\n",
    "                    qml.adjoint(qml.BasicEntanglerLayers)(params[2*l+1:2*l+2, :], wires=device.wires, rotation=qml.RY)\n",
    "            \n",
    "            parameter_shape = (2*n_layers, n_qubits)\n",
    "            # parameter_shape = qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=device.num_wires) # TODO: var_form architechure\n",
    "            qasvm = PseudoTensorSoftQASVM(data=train_kernel, label=y_train, C=C, lamda=lamda, device=device, feature_map=None, var_form=var_form)\n",
    "            params=qml.numpy.random.random(parameter_shape, requires_grad=True)\n",
    "            for l in range(n_layers):\n",
    "                params[2*l:2*l+1, :] = params[2*l+1:2*l+2, :]\n",
    "            opt = qml.AdamOptimizer(stepsize=stepsize)\n",
    "            cost_list = []\n",
    "            for step in range(1, n_steps+1):\n",
    "                params, cost = opt.step_and_cost(qasvm.cost_fn, params)\n",
    "                cost_list.append(cost.item())\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar('Training/Cost', cost_list[-1], step)\n",
    "            # test\n",
    "            cost = qasvm.cost_fn(params.numpy()).item()\n",
    "            fvec = qasvm.f(test_kernel, params.numpy()).numpy()\n",
    "            accuracy = accuracy_score(np.where(fvec>0, 1, 0), y_test)\n",
    "            epsilon_summary[n_qubits][n_layers] = epsilon(fvec, true_fvec)\n",
    "            delta_summary[n_qubits][n_layers] = cost-true_cost\n",
    "            accuracy_summary[n_qubits][n_layers] = accuracy\n",
    "            summary_writer.add_figure('Test/epsilon', make_figure(epsilon_summary))\n",
    "            summary_writer.add_figure('Test/delta', make_figure(delta_summary))\n",
    "            summary_writer.add_figure('Test/accuracy', make_figure(accuracy_summary))\n",
    "            # save result\n",
    "            with open(sub_sub_dir_path/'result.json', 'w') as fp:\n",
    "                json.dump(dict(\n",
    "                    accuracy=accuracy, last_cost = cost, fvec=fvec, cost_list=cost_list\n",
    "                ), fp=fp, default=list)\n",
    "            epsilon_summary.to_csv(dir_path/'epsilon_summary')\n",
    "            delta_summary.to_csv(dir_path/'delta_summary')\n",
    "            accuracy_summary.to_csv(dir_path/'accuracy_summary')\n",
    "            reference_accuracy_summary.to_csv(dir_path/'reference_accuracy_summary')\n",
    "            reference_cost_summary.to_csv(dir_path/'reference_cost_summary')\n",
    "        else:\n",
    "            print(f'Already done for {n_qubits} qubits {n_layers} layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('qiskit': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86394d4aecdf90bfa3aa767d508cb9549ad3b678679daec23858fa7c305a4457"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
