{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from matplotlib import pyplot as plt\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit.providers.aer import StatevectorSimulator\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pandas import DataFrame\n",
    "\n",
    "sys.path.extend(['/home/quic/QUIC-Projects/'])\n",
    "from classifiers.quantum.qml.qasvm import PseudoTensorSoftQASVM\n",
    "from classifiers.datasets.sklearn import SklearnDataset\n",
    "from classifiers.quantum.ansatz import MultilayerCircuit9FeatureMap\n",
    "from classifiers.convex.svm import CvxSoftQASVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation setting\n",
    "n_samples = 200\n",
    "n_feature = 10\n",
    "n_qubits_list = np.arange(6, 13+1, dtype=int) # 6 7 8 9 10 11 12 13\n",
    "n_layers_list = np.arange(1, 19+1, 2, dtype=int) # 1 3 5 7 9 11 13 15 17 19\n",
    "C=10**3\n",
    "lamda=10**3\n",
    "dir_name = 'numerical_simulation_bp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(dataset, train_size:float=2**13, reproducible_seed:int=None):\n",
    "    data = dataset.data.to_numpy()\n",
    "    label = dataset.target.to_numpy().astype(float)\n",
    "    # label = np.where(label%2, 1, 0)\n",
    "    mask = (label==0) + (label==1)\n",
    "    data = data[mask]\n",
    "    label = label[mask]\n",
    "    if reproducible_seed is None:\n",
    "        reproducible_seed = np.random.randint(99999)\n",
    "    X_train, _, y_train, _ = train_test_split(data, label, train_size=train_size, test_size=1, random_state=reproducible_seed)\n",
    "    return X_train, y_train, reproducible_seed\n",
    "\n",
    "def reduce_and_normalize_data(n_components, X_train):\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    for i, d in enumerate(X_train):\n",
    "        X_train[i] = d/np.linalg.norm(d)\n",
    "    return X_train\n",
    "\n",
    "def construct_training_quantum_kernel_matrix(feature_map:QuantumCircuit, X_train:np.ndarray):\n",
    "    quantum_instance = QuantumInstance(backend = StatevectorSimulator(device='CPU')) # TODO: gpu vs cpu\n",
    "    quantum_kernel = QuantumKernel(feature_map=feature_map, quantum_instance=quantum_instance, enforce_psd=False)\n",
    "    training_kernel = quantum_kernel.evaluate(X_train, X_train)\n",
    "    return training_kernel\n",
    "\n",
    "def epsilon(fvec, true_fvec):\n",
    "    return np.sqrt(np.mean(np.abs(fvec-true_fvec)**2)).item()\n",
    "\n",
    "def make_figure(df:DataFrame):\n",
    "    fig, ax = plt.subplots()\n",
    "    mappable = ax.imshow(df, cmap='binary')\n",
    "    ax.set_xlabel('n_qubits')\n",
    "    ax.set_ylabel('n_layers')\n",
    "    ax.set_xticks(np.arange(len(n_qubits_list)))\n",
    "    ax.set_yticks(np.arange(len(n_layers_list)))\n",
    "    ax.set_xticklabels(n_qubits_list)\n",
    "    ax.set_yticklabels(n_layers_list)\n",
    "    fig.colorbar(mappable)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mnist data set\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "dir_path = Path.cwd() / dir_name\n",
    "dir_path.mkdir(parents=True, exist_ok=True)\n",
    "dataset = fetch_openml('mnist_784')\n",
    "print('loaded mnist data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 X 64 train kernel matrix generated for 1 layers (seed: 35098)\n",
      "64 X 64 train kernel matrix generated for 3 layers (seed: 40978)\n",
      "64 X 64 train kernel matrix generated for 5 layers (seed: 22574)\n",
      "64 X 64 train kernel matrix generated for 7 layers (seed: 75072)\n",
      "64 X 64 train kernel matrix generated for 9 layers (seed: 88867)\n",
      "64 X 64 train kernel matrix generated for 11 layers (seed: 34037)\n",
      "64 X 64 train kernel matrix generated for 13 layers (seed: 73726)\n",
      "64 X 64 train kernel matrix generated for 15 layers (seed: 29477)\n",
      "64 X 64 train kernel matrix generated for 17 layers (seed: 5095)\n",
      "64 X 64 train kernel matrix generated for 19 layers (seed: 86038)\n",
      "128 X 128 train kernel matrix generated for 1 layers (seed: 30510)\n",
      "128 X 128 train kernel matrix generated for 3 layers (seed: 90519)\n",
      "128 X 128 train kernel matrix generated for 5 layers (seed: 36372)\n",
      "128 X 128 train kernel matrix generated for 7 layers (seed: 76106)\n",
      "128 X 128 train kernel matrix generated for 9 layers (seed: 6266)\n",
      "128 X 128 train kernel matrix generated for 11 layers (seed: 38227)\n",
      "128 X 128 train kernel matrix generated for 13 layers (seed: 43364)\n",
      "128 X 128 train kernel matrix generated for 15 layers (seed: 47702)\n",
      "128 X 128 train kernel matrix generated for 17 layers (seed: 4939)\n",
      "128 X 128 train kernel matrix generated for 19 layers (seed: 6081)\n",
      "256 X 256 train kernel matrix generated for 1 layers (seed: 49529)\n",
      "256 X 256 train kernel matrix generated for 3 layers (seed: 96209)\n",
      "256 X 256 train kernel matrix generated for 5 layers (seed: 48197)\n",
      "256 X 256 train kernel matrix generated for 7 layers (seed: 17341)\n",
      "256 X 256 train kernel matrix generated for 9 layers (seed: 8056)\n",
      "256 X 256 train kernel matrix generated for 11 layers (seed: 55784)\n",
      "256 X 256 train kernel matrix generated for 13 layers (seed: 51189)\n",
      "256 X 256 train kernel matrix generated for 15 layers (seed: 54916)\n",
      "256 X 256 train kernel matrix generated for 17 layers (seed: 54750)\n",
      "256 X 256 train kernel matrix generated for 19 layers (seed: 96479)\n",
      "512 X 512 train kernel matrix generated for 1 layers (seed: 8747)\n",
      "512 X 512 train kernel matrix generated for 3 layers (seed: 4311)\n",
      "512 X 512 train kernel matrix generated for 5 layers (seed: 96162)\n",
      "512 X 512 train kernel matrix generated for 7 layers (seed: 56322)\n",
      "512 X 512 train kernel matrix generated for 9 layers (seed: 63058)\n",
      "512 X 512 train kernel matrix generated for 11 layers (seed: 14880)\n",
      "512 X 512 train kernel matrix generated for 13 layers (seed: 5140)\n",
      "512 X 512 train kernel matrix generated for 15 layers (seed: 97450)\n",
      "512 X 512 train kernel matrix generated for 17 layers (seed: 83735)\n",
      "512 X 512 train kernel matrix generated for 19 layers (seed: 93642)\n",
      "1024 X 1024 train kernel matrix generated for 1 layers (seed: 25986)\n",
      "1024 X 1024 train kernel matrix generated for 3 layers (seed: 82845)\n",
      "1024 X 1024 train kernel matrix generated for 5 layers (seed: 47317)\n",
      "1024 X 1024 train kernel matrix generated for 7 layers (seed: 19281)\n",
      "1024 X 1024 train kernel matrix generated for 9 layers (seed: 46616)\n",
      "1024 X 1024 train kernel matrix generated for 11 layers (seed: 6467)\n",
      "1024 X 1024 train kernel matrix generated for 13 layers (seed: 63780)\n",
      "1024 X 1024 train kernel matrix generated for 15 layers (seed: 81677)\n",
      "1024 X 1024 train kernel matrix generated for 17 layers (seed: 67260)\n",
      "1024 X 1024 train kernel matrix generated for 19 layers (seed: 90474)\n",
      "2048 X 2048 train kernel matrix generated for 1 layers (seed: 97376)\n",
      "2048 X 2048 train kernel matrix generated for 3 layers (seed: 39042)\n",
      "2048 X 2048 train kernel matrix generated for 5 layers (seed: 22906)\n",
      "2048 X 2048 train kernel matrix generated for 7 layers (seed: 21189)\n",
      "2048 X 2048 train kernel matrix generated for 9 layers (seed: 33838)\n",
      "2048 X 2048 train kernel matrix generated for 11 layers (seed: 49270)\n",
      "2048 X 2048 train kernel matrix generated for 13 layers (seed: 30303)\n",
      "2048 X 2048 train kernel matrix generated for 15 layers (seed: 65574)\n",
      "2048 X 2048 train kernel matrix generated for 17 layers (seed: 15931)\n",
      "2048 X 2048 train kernel matrix generated for 19 layers (seed: 47566)\n",
      "4096 X 4096 train kernel matrix generated for 1 layers (seed: 98126)\n",
      "4096 X 4096 train kernel matrix generated for 3 layers (seed: 37140)\n",
      "4096 X 4096 train kernel matrix generated for 5 layers (seed: 76269)\n",
      "4096 X 4096 train kernel matrix generated for 7 layers (seed: 77382)\n",
      "4096 X 4096 train kernel matrix generated for 9 layers (seed: 75318)\n",
      "4096 X 4096 train kernel matrix generated for 11 layers (seed: 75546)\n",
      "4096 X 4096 train kernel matrix generated for 13 layers (seed: 74163)\n",
      "4096 X 4096 train kernel matrix generated for 15 layers (seed: 62337)\n",
      "4096 X 4096 train kernel matrix generated for 17 layers (seed: 67040)\n",
      "4096 X 4096 train kernel matrix generated for 19 layers (seed: 81967)\n",
      "8192 X 8192 train kernel matrix generated for 1 layers (seed: 15524)\n",
      "8192 X 8192 train kernel matrix generated for 3 layers (seed: 12467)\n",
      "8192 X 8192 train kernel matrix generated for 5 layers (seed: 82128)\n",
      "8192 X 8192 train kernel matrix generated for 7 layers (seed: 20284)\n",
      "8192 X 8192 train kernel matrix generated for 9 layers (seed: 12683)\n",
      "8192 X 8192 train kernel matrix generated for 11 layers (seed: 28283)\n",
      "8192 X 8192 train kernel matrix generated for 13 layers (seed: 31236)\n",
      "8192 X 8192 train kernel matrix generated for 15 layers (seed: 17528)\n",
      "8192 X 8192 train kernel matrix generated for 17 layers (seed: 10630)\n",
      "8192 X 8192 train kernel matrix generated for 19 layers (seed: 94492)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "if dir_path.joinpath('grad_exp_summary').exists():\n",
    "    grad_exp_summary = read_csv(dir_path.joinpath('grad_exp_summary'), index_col=0)\n",
    "    grad_exp_summary.columns = grad_exp_summary.columns.astype(int)\n",
    "else:\n",
    "    grad_exp_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('grad_var_summary').exists():\n",
    "    grad_var_summary = read_csv(dir_path.joinpath('grad_var_summary'), index_col=0)\n",
    "    grad_var_summary.columns = grad_var_summary.columns.astype(int)\n",
    "else:\n",
    "    grad_var_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "\n",
    "# summary_writer = SummaryWriter(log_dir=dir_path)\n",
    "feature_map = ZZFeatureMap(feature_dimension=n_feature, reps=2, entanglement='linear')\n",
    "for n_qubits in n_qubits_list:\n",
    "    sub_dir_path = dir_path / f'n_qubits={n_qubits}'\n",
    "    sub_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=sub_dir_path)\n",
    "    train_size = 2**n_qubits\n",
    "\n",
    "    # ansatz setup\n",
    "    device:qml.Device = qml.device('lightning.qubit', wires=n_qubits) # TODO: gpu vs cpu\n",
    "    def var_form(params):\n",
    "        for w in device.wires:\n",
    "            qml.Hadamard(wires=w)\n",
    "        qml.BasicEntanglerLayers(params, wires=device.wires, rotation=qml.RY)\n",
    "        # qml.StronglyEntanglingLayers(params, wires=device.wires) # TODO: var_form architechure\n",
    "    for n_layers in n_layers_list:\n",
    "        sub_sub_dir_path = sub_dir_path / f'n_layers={n_layers}'\n",
    "        sub_sub_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        if not sub_sub_dir_path.joinpath('result.json').exists():\n",
    "            # data loading\n",
    "            if not sub_sub_dir_path.joinpath('reference.json').exists():\n",
    "                X_train, y_train, reproducible_seed = load_train_data(dataset, train_size=train_size)\n",
    "                X_train = reduce_and_normalize_data(n_feature, X_train)\n",
    "                train_kernel = construct_training_quantum_kernel_matrix(feature_map=feature_map, X_train=X_train)\n",
    "                # save reference key\n",
    "                with open(sub_sub_dir_path/'reference.json', 'w') as fp:\n",
    "                    json.dump(dict(seed = reproducible_seed), fp=fp, default=list)\n",
    "            else:\n",
    "                with open(sub_sub_dir_path/'reference.json', 'r') as fp:\n",
    "                    reference = json.load(fp=fp)\n",
    "                reproducible_seed = reference['seed']\n",
    "                print(f'Reference loaded for {n_qubits} qubits {n_layers} layers (seed: {reproducible_seed})')\n",
    "                X_train, y_train, _ = load_train_data(dataset, train_size=train_size, reproducible_seed=reproducible_seed)\n",
    "                X_train = reduce_and_normalize_data(n_feature, X_train)\n",
    "                train_kernel = construct_training_quantum_kernel_matrix(feature_map=feature_map, X_train=X_train)\n",
    "            print(f'{train_size} X {train_size} train kernel matrix generated for {n_layers} layers (seed: {reproducible_seed})')\n",
    "            # gradient measurement\n",
    "            parameter_shape = qml.BasicEntanglerLayers.shape(n_layers=n_layers, n_wires=device.num_wires)\n",
    "            # parameter_shape = qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=device.num_wires) # TODO: var_form architechure\n",
    "            qasvm = PseudoTensorSoftQASVM(data=train_kernel, label=y_train, C=C, lamda=lamda, device=device, feature_map=None, var_form=var_form)\n",
    "            # grad_results = np.empty(shape=(n_samples, *parameter_shape))\n",
    "            grad_results = np.empty(shape=(n_samples,))\n",
    "            # grad_fn = qml.jacobian(qasvm.cost_fn)\n",
    "            # grad_fn = qml.jacobian(qasvm.avg_f)\n",
    "            for s in range(n_samples):\n",
    "                params=qml.numpy.random.random(parameter_shape, requires_grad=True)\n",
    "                grad_results[s] = qasvm.grad_fn_00(params)\n",
    "            # grad_results_00 = grad_results[:, 0, 0]\n",
    "            grad_results_00 = grad_results[:]\n",
    "            grad_exp = grad_results_00.mean()\n",
    "            grad_var = grad_results_00.var()\n",
    "            grad_exp_summary[n_qubits][n_layers] = grad_exp\n",
    "            grad_var_summary[n_qubits][n_layers] = grad_var\n",
    "            writer.add_scalar('Grad/Expectation', grad_exp, n_layers)\n",
    "            writer.add_scalar('Grad/Variance', grad_var, n_layers)\n",
    "            writer.add_scalar('Log10Grad/AbsExpectation', np.log10(np.abs(grad_exp)), n_layers)\n",
    "            writer.add_scalar('Log10Grad/Variance', np.log10(grad_var), n_layers)\n",
    "            # save result\n",
    "            with open(sub_sub_dir_path/'result.json', 'w') as fp:\n",
    "                json.dump(dict(grad_results = grad_results.tolist(), sample_size=n_samples), fp=fp, default=list)\n",
    "            grad_exp_summary.to_csv(dir_path/'grad_exp_summary')\n",
    "            grad_var_summary.to_csv(dir_path/'grad_var_summary')\n",
    "        else:\n",
    "            print(f'Already done for {n_qubits} qubits {n_layers} layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('qiskit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86394d4aecdf90bfa3aa767d508cb9549ad3b678679daec23858fa7c305a4457"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
