{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from matplotlib import pyplot as plt\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit.providers.aer import StatevectorSimulator\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pandas import DataFrame\n",
    "\n",
    "sys.path.extend(['/home/quic/QUIC-Projects/'])\n",
    "from classifiers.quantum.qml.qasvm import PseudoTensorSoftQASVM\n",
    "from classifiers.datasets.sklearn import SklearnDataset\n",
    "from classifiers.quantum.ansatz import MultilayerCircuit9FeatureMap\n",
    "from classifiers.convex.svm import CvxSoftQASVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation setting\n",
    "test_size = 14780-2**13 #2**13\n",
    "n_steps = 2**10\n",
    "stepsize = 0.001\n",
    "n_feature = 10\n",
    "n_qubits_list = np.arange(6, 13+1, dtype=int) # 6 7 8 9 10 11 12 13\n",
    "n_layers_list = np.arange(1, 19+1, 2, dtype=int) # 1 3 5 7 9 11 13 15 17 19\n",
    "C=10**3\n",
    "lamda=10**3\n",
    "dir_name = 'numerical_simulation_gpu2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_and_test_data(dataset, train_size:float=2**13, test_size:float=2**7, reproducible_seed:int=None):\n",
    "    data = dataset.data.to_numpy()\n",
    "    label = dataset.target.to_numpy().astype(float)\n",
    "    # label = np.where(label%2, 1, 0)\n",
    "    mask = (label==0) + (label==1)\n",
    "    data = data[mask]\n",
    "    label = label[mask]\n",
    "    if reproducible_seed is None:\n",
    "        reproducible_seed = np.random.randint(99999)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, train_size=train_size, test_size=test_size, random_state=reproducible_seed)\n",
    "    return X_train, y_train, X_test, y_test, reproducible_seed\n",
    "\n",
    "def reduce_and_normalize_data(n_components, X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = pca.transform(X_test)\n",
    "    for i, d in enumerate(X_train):\n",
    "        X_train[i] = d/np.linalg.norm(d)\n",
    "    for i, d in enumerate(X_test):\n",
    "        X_test[i] = d/np.linalg.norm(d)\n",
    "    return X_train, X_test\n",
    "\n",
    "def construct_training_and_test_quantum_kernel_matrix(feature_map:QuantumCircuit, X_train:np.ndarray, X_test:np.ndarray):\n",
    "    quantum_instance = QuantumInstance(backend = StatevectorSimulator(device='CPU')) # TODO: gpu vs cpu\n",
    "    quantum_kernel = QuantumKernel(feature_map=feature_map, quantum_instance=quantum_instance, enforce_psd=False)\n",
    "    training_kernel = quantum_kernel.evaluate(X_train, X_train)\n",
    "    test_kernel = quantum_kernel.evaluate(X_train, X_test)\n",
    "    return training_kernel, test_kernel\n",
    "\n",
    "def train_and_test_reference(cvxsvm:CvxSoftQASVM, train_kernel:np.ndarray, test_kernel:np.ndarray, y_train:np.ndarray, y_test:np.ndarray):\n",
    "    cvxsvm.fit(train_kernel, y_train)\n",
    "    fvec = cvxsvm.f(test_kernel.T)\n",
    "    accuarcy = cvxsvm.accuracy(test_kernel.T, y_test)\n",
    "    cost = cvxsvm.dual_objective_value\n",
    "    return fvec, accuarcy, cost\n",
    "\n",
    "def epsilon(fvec, true_fvec):\n",
    "    return np.sqrt(np.mean(np.abs(fvec-true_fvec)**2)).item()\n",
    "\n",
    "def make_figure(df:DataFrame):\n",
    "    fig, ax = plt.subplots()\n",
    "    mappable = ax.imshow(df, cmap='binary')\n",
    "    ax.set_xlabel('n_qubits')\n",
    "    ax.set_ylabel('n_layers')\n",
    "    ax.set_xticks(np.arange(len(n_qubits_list)))\n",
    "    ax.set_yticks(np.arange(len(n_layers_list)))\n",
    "    ax.set_xticklabels(n_qubits_list)\n",
    "    ax.set_yticklabels(n_layers_list)\n",
    "    fig.colorbar(mappable)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mnist data set\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "dir_path = Path.cwd() / dir_name\n",
    "dir_path.mkdir(parents=True, exist_ok=True)\n",
    "dataset = fetch_openml('mnist_784')\n",
    "print('loaded mnist data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already done for 6 qubits 1 layers\n",
      "Already done for 6 qubits 3 layers\n",
      "Already done for 6 qubits 5 layers\n",
      "Already done for 6 qubits 7 layers\n",
      "Already done for 6 qubits 9 layers\n",
      "Already done for 6 qubits 11 layers\n",
      "Already done for 6 qubits 13 layers\n",
      "Already done for 6 qubits 15 layers\n",
      "Already done for 6 qubits 17 layers\n",
      "Already done for 6 qubits 19 layers\n",
      "Already done for 7 qubits 1 layers\n",
      "Already done for 7 qubits 3 layers\n",
      "Already done for 7 qubits 5 layers\n",
      "Already done for 7 qubits 7 layers\n",
      "Already done for 7 qubits 9 layers\n",
      "Already done for 7 qubits 11 layers\n",
      "Already done for 7 qubits 13 layers\n",
      "Already done for 7 qubits 15 layers\n",
      "Already done for 7 qubits 17 layers\n",
      "Already done for 7 qubits 19 layers\n",
      "Already done for 8 qubits 1 layers\n",
      "Already done for 8 qubits 3 layers\n",
      "Already done for 8 qubits 5 layers\n",
      "Already done for 8 qubits 7 layers\n",
      "Already done for 8 qubits 9 layers\n",
      "Already done for 8 qubits 11 layers\n",
      "Already done for 8 qubits 13 layers\n",
      "Already done for 8 qubits 15 layers\n",
      "Already done for 8 qubits 17 layers\n",
      "Already done for 8 qubits 19 layers\n",
      "Already done for 9 qubits 1 layers\n",
      "Already done for 9 qubits 3 layers\n",
      "Already done for 9 qubits 5 layers\n",
      "Already done for 9 qubits 7 layers\n",
      "Already done for 9 qubits 9 layers\n",
      "Already done for 9 qubits 11 layers\n",
      "Already done for 9 qubits 13 layers\n",
      "Already done for 9 qubits 15 layers\n",
      "Already done for 9 qubits 17 layers\n",
      "Already done for 9 qubits 19 layers\n",
      "Already done for 10 qubits 1 layers\n",
      "Already done for 10 qubits 3 layers\n",
      "Already done for 10 qubits 5 layers\n",
      "Already done for 10 qubits 7 layers\n",
      "Already done for 10 qubits 9 layers\n",
      "Already done for 10 qubits 11 layers\n",
      "Already done for 10 qubits 13 layers\n",
      "Already done for 10 qubits 15 layers\n",
      "Already done for 10 qubits 17 layers\n",
      "Already done for 10 qubits 19 layers\n",
      "Already done for 11 qubits 1 layers\n",
      "Already done for 11 qubits 3 layers\n",
      "Already done for 11 qubits 5 layers\n",
      "Already done for 11 qubits 7 layers\n",
      "Already done for 11 qubits 9 layers\n",
      "Already done for 11 qubits 11 layers\n",
      "Already done for 11 qubits 13 layers\n",
      "Already done for 11 qubits 15 layers\n",
      "Already done for 11 qubits 17 layers\n",
      "Already done for 11 qubits 19 layers\n",
      "Already done for 12 qubits 1 layers\n",
      "Already done for 12 qubits 3 layers\n",
      "Already done for 12 qubits 5 layers\n",
      "Already done for 12 qubits 7 layers\n",
      "Already done for 12 qubits 9 layers\n",
      "Already done for 12 qubits 11 layers\n",
      "Already done for 12 qubits 13 layers\n",
      "Already done for 12 qubits 15 layers\n",
      "Reference loaded for 12 qubits 17 layers (seed: 65854)\n",
      "4096 X 4096 train kernel matrix and 4096 X 6588 test kernel matrix generated for 17 layers (seed: 65854)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda/envs/qiskit/lib/python3.9/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda/envs/qiskit/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda/envs/qiskit/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m fvec \u001b[38;5;241m=\u001b[39m qasvm\u001b[38;5;241m.\u001b[39mf(test_kernel, params\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     86\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(np\u001b[38;5;241m.\u001b[39mwhere(fvec\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), y_test)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mepsilon_summary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn_qubits\u001b[49m\u001b[43m]\u001b[49m[n_layers] \u001b[38;5;241m=\u001b[39m epsilon(fvec, true_fvec)\n\u001b[1;32m     88\u001b[0m delta_summary[n_qubits][n_layers] \u001b[38;5;241m=\u001b[39m cost\u001b[38;5;241m-\u001b[39mtrue_cost\n\u001b[1;32m     89\u001b[0m accuracy_summary[n_qubits][n_layers] \u001b[38;5;241m=\u001b[39m accuracy\n",
      "File \u001b[0;32m~/anaconda/envs/qiskit/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda/envs/qiskit/lib/python3.9/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 12"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "if dir_path.joinpath('epsilon_summary').exists():\n",
    "    epsilon_summary = read_csv(dir_path.joinpath('epsilon_summary'), index_col=0)\n",
    "    epsilon_summary.columns = epsilon_summary.columns.astype(int)\n",
    "else:\n",
    "    epsilon_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('delta_summary').exists():\n",
    "    delta_summary = read_csv(dir_path.joinpath('delta_summary'), index_col=0)\n",
    "    delta_summary.columns = delta_summary.columns.astype(int)\n",
    "else:\n",
    "    delta_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('accuracy_summary').exists():\n",
    "    accuracy_summary = read_csv(dir_path.joinpath('accuracy_summary'), index_col=0)\n",
    "    accuracy_summary.columns = accuracy_summary.columns.astype(int)\n",
    "else:\n",
    "    accuracy_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('reference_accuracy_summary').exists():\n",
    "    reference_accuracy_summary = read_csv(dir_path.joinpath('reference_accuracy_summary'), index_col=0)\n",
    "    reference_accuracy_summary.columns = reference_accuracy_summary.columns.astype(int)\n",
    "else:\n",
    "    reference_accuracy_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "if dir_path.joinpath('reference_cost_summary').exists():\n",
    "    reference_cost_summary = read_csv(dir_path.joinpath('reference_cost_summary'), index_col=0)\n",
    "    reference_cost_summary.columns = reference_cost_summary.columns.astype(int)\n",
    "else:\n",
    "    reference_cost_summary = DataFrame({n_qubits:dict(zip(n_layers_list, np.zeros_like(n_layers_list))) for n_qubits in n_qubits_list}, dtype=float)\n",
    "\n",
    "summary_writer = SummaryWriter(log_dir=dir_path)\n",
    "feature_map = ZZFeatureMap(feature_dimension=n_feature, reps=2, entanglement='linear')\n",
    "for n_qubits in n_qubits_list:\n",
    "    sub_dir_path = dir_path / f'n_qubits={n_qubits}'\n",
    "    sub_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    train_size = 2**n_qubits\n",
    "\n",
    "    # ansatz setup\n",
    "    device:qml.Device = qml.device('lightning.qubit', wires=n_qubits) # TODO: gpu vs cpu\n",
    "    def var_form(params):\n",
    "        qml.BasicEntanglerLayers(params, wires=device.wires, rotation=qml.RY)\n",
    "        # qml.StronglyEntanglingLayers(params, wires=device.wires) # TODO: var_form architechure\n",
    "    for n_layers in n_layers_list:\n",
    "        sub_sub_dir_path = sub_dir_path / f'n_layers={n_layers}'\n",
    "        sub_sub_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        if not sub_sub_dir_path.joinpath('result.json').exists():\n",
    "            writer = SummaryWriter(log_dir=sub_sub_dir_path)\n",
    "            # data loading\n",
    "            if not sub_sub_dir_path.joinpath('reference.json').exists():\n",
    "                X_train, y_train, X_test, y_test, reproducible_seed = load_train_and_test_data(dataset, train_size=train_size, test_size=test_size)\n",
    "                X_train, X_test = reduce_and_normalize_data(n_feature, X_train, X_test)\n",
    "                train_kernel, test_kernel = construct_training_and_test_quantum_kernel_matrix(feature_map=feature_map, X_train=X_train, X_test=X_test)\n",
    "                print(f'{train_size} X {train_size} train kernel matrix and {train_size} X {test_size} test kernel matrix generated for {n_layers} layers (seed: {reproducible_seed})')\n",
    "                # set reference\n",
    "                cvxsvm = CvxSoftQASVM(kernel='precomputed', C=C, lamda=lamda)\n",
    "                true_fvec, true_accuarcy, true_cost = train_and_test_reference(cvxsvm, train_kernel, test_kernel, y_train, y_test)\n",
    "                reference_accuracy_summary[n_qubits][n_layers] = true_accuarcy\n",
    "                reference_cost_summary[n_qubits][n_layers] = true_cost\n",
    "                summary_writer.add_figure('Reference/cost', make_figure(reference_cost_summary))\n",
    "                summary_writer.add_figure('Reference/accuracy', make_figure(reference_accuracy_summary))\n",
    "                # save reference key\n",
    "                with open(sub_sub_dir_path/'reference.json', 'w') as fp:\n",
    "                    json.dump(dict(\n",
    "                        accuracy=true_accuarcy, last_cost = true_cost, fvec=true_fvec, seed = reproducible_seed\n",
    "                    ), fp=fp, default=list)\n",
    "            else:\n",
    "                with open(sub_sub_dir_path/'reference.json', 'r') as fp:\n",
    "                    reference = json.load(fp=fp)\n",
    "                true_accuarcy, true_cost = reference['accuracy'], reference['last_cost']\n",
    "                true_fvec = np.array(reference['fvec'])\n",
    "                reproducible_seed = reference['seed']\n",
    "                print(f'Reference loaded for {n_qubits} qubits {n_layers} layers (seed: {reproducible_seed})')\n",
    "                X_train, y_train, X_test, y_test, _ = load_train_and_test_data(dataset, train_size=train_size, test_size=test_size, reproducible_seed=reproducible_seed)\n",
    "                X_train, X_test = reduce_and_normalize_data(n_feature, X_train, X_test)\n",
    "                train_kernel, test_kernel = construct_training_and_test_quantum_kernel_matrix(feature_map=feature_map, X_train=X_train, X_test=X_test)\n",
    "                print(f'{train_size} X {train_size} train kernel matrix and {train_size} X {test_size} test kernel matrix generated for {n_layers} layers (seed: {reproducible_seed})')\n",
    "            # training\n",
    "            parameter_shape = qml.BasicEntanglerLayers.shape(n_layers=n_layers, n_wires=device.num_wires)\n",
    "            # parameter_shape = qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=device.num_wires) # TODO: var_form architechure\n",
    "            qasvm = PseudoTensorSoftQASVM(data=train_kernel, label=y_train, C=C, lamda=lamda, device=device, feature_map=None, var_form=var_form)\n",
    "            params=qml.numpy.random.random(parameter_shape, requires_grad=True)\n",
    "            opt = qml.AdamOptimizer(stepsize=stepsize)\n",
    "            cost_list = []\n",
    "            for step in range(1, n_steps+1):\n",
    "                params, cost = opt.step_and_cost(qasvm.cost_fn, params)\n",
    "                cost_list.append(cost.item())\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar('Training/Cost', cost_list[-1], step)\n",
    "                    #writer.add_scalar('Training/Normal_Cost', (cost_list[-1]-true_cost)/(cost_list[0]-true_cost), step)\n",
    "            # test\n",
    "            cost = qasvm.cost_fn(params.numpy()).item()\n",
    "            fvec = qasvm.f(test_kernel, params.numpy()).numpy()\n",
    "            accuracy = accuracy_score(np.where(fvec>0, 1, 0), y_test)\n",
    "            epsilon_summary[n_qubits][n_layers] = epsilon(fvec, true_fvec)\n",
    "            delta_summary[n_qubits][n_layers] = cost-true_cost\n",
    "            accuracy_summary[n_qubits][n_layers] = accuracy\n",
    "            summary_writer.add_figure('Test/epsilon', make_figure(epsilon_summary))\n",
    "            summary_writer.add_figure('Test/delta', make_figure(delta_summary))\n",
    "            summary_writer.add_figure('Test/accuracy', make_figure(accuracy_summary))\n",
    "            # save result\n",
    "            with open(sub_sub_dir_path/'result.json', 'w') as fp:\n",
    "                json.dump(dict(\n",
    "                    accuracy=accuracy, last_cost = cost, fvec=fvec, cost_list=cost_list\n",
    "                ), fp=fp, default=list)\n",
    "            epsilon_summary.to_csv(dir_path/'epsilon_summary')\n",
    "            delta_summary.to_csv(dir_path/'delta_summary')\n",
    "            accuracy_summary.to_csv(dir_path/'accuracy_summary')\n",
    "            reference_accuracy_summary.to_csv(dir_path/'reference_accuracy_summary')\n",
    "            reference_cost_summary.to_csv(dir_path/'reference_cost_summary')\n",
    "        else:\n",
    "            print(f'Already done for {n_qubits} qubits {n_layers} layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('qiskit': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86394d4aecdf90bfa3aa767d508cb9549ad3b678679daec23858fa7c305a4457"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
